# Что такое динамическое программирование?



Оглавление



## Мотивация

Работа разработчика состоит из решения головоломок. Многие из этих головоломок имеют эффективное решение *(расшить, что понимаем под эффективным решением)*, но некоторые возможно решить только перебором всех возможных вариантов *(если возможно, привести пример такой задачи)*. По крайней мере, такое впечатление складывается при первом знакомстве с этими задачами. 

Решение полным перебором часто называют решением в лоб, методом грубой силы или наивным решением *(предложил бы оставить только одно именование, немного шире расписав, почему оно такое)* . Такие решения имеют очевидный минус — они очень затратны. Практические любое неоптимизированное решение перебором будет стоить экспоненциального времени, например O(2^n), где n — это количество элементов в нашей задаче. Такими элементами могут быть ячейки массива, узлы графа, объекты из предметной области — всё что угодно *(переписать этот блок, более простым языком обозначив, как и почему такое решение - не лучшее)*. 

Это очень плохое время работы *(избегать оценок вида "хороший", "плохой", "лёгкий", "очевидный)* . Настолько плохое, что никому и в голову не придёт запустить такой алгоритм даже на простых данных, ведь на решение такой задачи с сотней элементов потребуются тысячи, миллионы или миллиарды лет вычислений. А в реальной жизни нужно решать задачи с намного большим количеством элементов. Как же быть?

Дело в том, что многие задачи без эффективного алгоритма решения можно решить за привлекательное время с помощью одной хитрости. Имя ей — динамическое программирование! Но давайте обо всём по порядку… *(последнее предложение убрать)*



## Динамическое программирование

Динамическое программирование это особый подход к решению задач. Основная его идея: оптимальное решение задачи можно собрать из решений её кусочков *(переформулировать: описать основнуб идею проще и более развёрнуто)*. В отличие от обычной рекурсии и решений по принципу “разделяй и властвуй”, решения задач в динамическом программировании обычно наращиваются с нуля, а не собираются из кусочков раздробленной исходной задачи *(не опираться на рекурсию, описать проще)*.

Магия динамического программирования заключается в умном обращении с решениями подзадач. “Умный” в этом контексте значит “не решающий одну и ту же подзадачу дважды”. Для этого решения мелких подзадач должны заботливо учитываться в подходящей структуре данных *(переформулировать предложение, например: "должны учитываться в подходящем виде)*. Для многих реальных алгоритмов динамического программирования этой структурой данных является таблица *(согласовать с предыдущим предложением после корректировок)*.

В самых простых случаях эта таблица будет состоять только из одной строки — аналогично обычному массиву. Эти случаи будут называться одномерным динамическим программированием, и потреблять O(n) памяти. Например, алгоритм эффективного вычисления чисел Фибоначчи использует простой массив для запоминания промежуточных результатов *(чуть шире и подробнее расшить этот блок)*.

В самых распространённых случаях эта таблица будет выглядеть привычно, из строчек и столбиков. Обычная таблица, похожая на таблицы из Excel. Это называется двумерным динамическим программированием, которое при n строках и n столбцах таблицы будет потреблять O(n*n) = O(n^2) памяти *(информацию о потреблении памяти расшить проще, либо исключить из этого фрагмента)*. Чуть ниже будет подробно разобрана именно такая задача.

Бывают и более запутанные задачи, использующие для решения трёхмерные таблицы, но это уже экзотика — O(n^3) памяти выглядит не сильно симпатичнее экспоненциального времени выполнения наивного решения *(описать проще, а-ля: "решение задачи с использованием трёхмерной таблицы сопоставима с простым перебором")*.

Что нужно, чтоб решить задачу динамически, помимо её исходных данных? Всего три вещи:

- Таблица, в которую будут вноситься промежуточные результаты. Один из них будет выбран в конце работы алгоритма в качестве ответа.
- Несколько простых правил по заполнению пустых ячеек таблицы, основываясь на значениях в уже заполненных ячейках. Универсального рецепта тут нет, и к каждой задаче требуется свой подход.
- Правило выбора финального решения после заполнения таблицы.

Много слов уже было сказано об идеях и принципах динамического программирования, но без разбора задачи — грош этой болтовне цена *(убрать предложение)*. Настало время наглядного примера *(переформулировать: "Разберём эти принципы на примере")*.

## Пример решения задачи

Демонстрационным подопытным выступит классическая задача динамического программирования — Расстояние Левенштейна. Звучит немножко пугающе *(переформулировать: "Несмотря на кажущееся сложным название, в действительности...")*, но на самом деле это задача об трансформации одного слова в другое путём добавления, удаления и замены букв с минимальным количеством операций. 

Не будем забираться в математическую формулировку, лучше сформулируем задачу на пальцах *(переформулировать: "Эта задача может быть сформулирована так:...")*.  

Наша задача: найти минимальное “расстояние” между двумя словами. Расстоянием в этом случае будет минимальное количество операций, которые нужно применить к первому слову, чтобы получить второе (или наоборот).

Доступных операции у нас три:

- insert — добавить одну букву в любое место в слове, в том числе в самое начало и в конец.
- delete — удалить одну букву из любого места в слове.
- replace — заменить одну букву на определённом месте на другую букву.

Все эти операции имеют равную стоимость: +1 к расстоянию между словами.

Возьмем для примера два простых слова, MONEY и MONKEY. Какое минимальное количество операций необходимо, чтоб превратить MONEY в MONKEY? Находчивый человеческий глаз быстро смекнёт, что одна: добавить букву K после между третьей и четвертой буквой.

Кажется очень простой задачей, правда? *(переформулировать: "Попробуем усложнить...")* Попробуйте *(обращение, здесь и далее: первое лицо мн.ч "попробуем", "превратим" etc.)* превратить слово SUNDAY в слово SATURDAY, и вы увидите, что количество комбинаций, которые нужно перебрать, потенциально очень велико. Если решать задачу в лоб *(перебором)*, то можно перебрать все возможные комбинации, рекурсивно применяя каждую из трёх представленных операций к каждой букве слова *(переформулировать проще)*. Каждая буква в первом слове будет порождать три ветки рекурсии, что приведет аж к O(3^n) операций в худшем случае *(расшать, сформулировать проще)*. 

### Динамическое решение

Приступим к динамическому решению!

Для начала, создадим таблицу, и разместим исходные слова на её краях, оставив немножко свободного места. Второй столбик и вторую строчку буем использовать для пустых строк — их часто обозначают символом ε, читается epsilon. Аналог того, что вы имеете в виду, когда используете пустую строку на своём языке программирования: String eps = “”.

|       |  ε   |  S   |  A   |  T   |  U   |  R   |  D   |  A   |  Y   |
| :---: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| **ε** |      |      |      |      |      |      |      |      |      |
| **S** |      |      |      |      |      |      |      |      |      |
| **U** |      |      |      |      |      |      |      |      |      |
| **N** |      |      |      |      |      |      |      |      |      |
| **D** |      |      |      |      |      |      |      |      |      |
| **A** |      |      |      |      |      |      |      |      |      |
| **Y** |      |      |      |      |      |      |      |      |      |

Теперь заполним второй столбик и вторую строчку, руководствуясь абсолютно интуитивными соображениями: как превратить пустую строку в какую-то строку? Конечно же, добавить в неё нужные символы! Например, чтоб перевести ε в SATU необходимо добавить букву S, букву A, букву T и букву U. Четыре операции. Что делать с превращением ε в ε (вторая строка, второй столбец)? Элементарно — ничего делать не нужно, ноль действий.

|       |  ε   |  S   |  A   |  T   |  U   |  R   |  D   |  A   |  Y   |
| :---: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| **ε** |  0   |  1   |  2   |  3   |  4   |  5   |  6   |  7   |  8   |
| **S** |  1   |      |      |      |      |      |      |      |      |
| **U** |  2   |      |      |      |      |      |      |      |      |
| **N** |  3   |      |      |      |      |      |      |      |      |
| **D** |  4   |      |      |      |      |      |      |      |      |
| **A** |  5   |      |      |      |      |      |      |      |      |
| **Y** |  6   |      |      |      |      |      |      |      |      |

Теперь нужна система простых правил, с помощью которой мы сможем заполнить таблицу. Таблица будет именоваться D, а первая строчка и столбик останутся на её полях. Работать с таблицей мы будем, как с двухмерным массивом: D[0, 2] означают ячейку на пересечении нулевой строки и второго столбика. В нашем примере D[0, 2] = 2.

Также назовём слово по вертикали A, а слово по горизонтали B. Эта парочка нам нужна, чтоб иметь доступ к оригинальным словам на полях. Из-за дополнительных колонок в для ε индексы в A и B отличаются от индексов в таблице. Если быть точнее — они сдвинуты на единицу. A[0] = S, A[1] = U, A[2] = N, B[7] = Y, и так далее.

Наконец, создадим наше правило заполнения таблицы. Для каждой новой ячейки мы проверяем верхнюю, левую или лево верхнюю по диагонали соседние ячейки. Из трёх чисел будет выбрано наименьшее и записано в новую ячейку.

*TODO сделать картинкой:*

```
D[i, j] = minimum(
	D[i-1, j] + 1,                              // delete
	D[i, j-1] + 1,                              // insert 
	D[i-1, j-1] + (A[i-1] == B[j-1] ? 1 : 0)    // replace 
)  
```

Это, несомненно, самый неприятный и сложный момент в динамическом программировании *(заменить на: "Это важный момент в динамическом программировании...")*: правила кажутся бессмысленными, не выходит собрать общую картину происходящего в голове. Давайте посмотрим на маленький кусочек таблицы, возможно, он прольёт свет на некоторые детали.

|       |  ε   |  S   |  A   |
| :---: | :--: | :--: | :--: |
| **ε** |  0   |  1   |  2   |
| **S** |  1   |      |      |
| **U** |  2   |      |      |

Что записать в ячейку D[1,1] как результат перехода из S в S? Интуитивно ясно, что для этого ничего делать и не нужно, ноль операций. Запишем ноль в ячейку. На что походит это значение, учитывая, что вычитать ничего нельзя? Среди соседей ноль есть только по диагонали.

|       |  ε   |  S   |  A   |
| :---: | :--: | :--: | :--: |
| **ε** |  0   |  1   |  2   |
| **S** |  1   |  0   |      |
| **U** |  2   |      |      |

Что записать в ячейку D[2,1] как результат перехода из SU в S? Нужно удалить букву U, значит, одна операция. По-сути, стоимость перехода из SU в S будет равно стоимости удаления буквы U и перехода из S в S (чья стоимость уже была посчитана и лежит в ячейке D[1,1]).

|       |  ε   |  S   |  A   |
| :---: | :--: | :--: | :--: |
| **ε** |  0   |  1   |  2   |
| **S** |  1   |  0   |      |
| **U** |  2   |  1   |      |

Теперь посмотрим на ячейку D[1,2], переход из S в SA. Да, именно, стоимость перехода будет равна стоимости добавления буквы A и перехода из S в S, итого единица.

|       |  ε   |  S   |  A   |
| :---: | :--: | :--: | :--: |
| **ε** |  0   |  1   |  2   |
| **S** |  1   |  0   |  1   |
| **U** |  2   |  1   |      |

Последняя ячейка, D[2,2], переход из SU в SA. Самым оптимальным решением было бы заменить букву U на букву A, плюс цена бесплатного перехода из S в S. 

|       |  ε   |  S   |  A   |
| :---: | :--: | :--: | :--: |
| **ε** |  0   |  1   |  2   |
| **S** |  1   |  0   |  1   |
| **U** |  2   |  1   |  1   |

В самой правой нижней ячейке содержится финальная стоимость перехода из слова SU в слово SA. Аналогичным образом можно заполнить всю таблицу! Великолепно, из ячейки D[6,8] мы узнали, что переход из слова SUNDAY в слово SATURDAY стоит минимум три операции. Жирным шрифтом выделим оптимальный путь. 

Давайте проследим его по шагам. Переход из S в S ничего не стоит. Переход из S в SA стоит одну операцию. Переход из S в SAT стоит две операции. Переход из SU в SATU стоит две операции. Переход из SUN в SATUR стоит три операции. Переход из SUND в SATURD стоит три операции (стоимость предыдущего перехода плюс нулевая цена перехода из D в D). Переход из SUNDA в SATURDA стоит три операции. Наконец, переход из SUNDAY в SATURDAY требует тех же трёх операций.

Кстати, если присмотреться к табличке, то можно заметить, что оптимальных решений несколько: из D[1,2] можно перейти как в D[1,3], так и в D[2,2]. В этой постановке задачи нас интересует только минимальное количество, а не список всех возможных путей решения, так что это не суть важно.

|       |  ε   |   S   |   A   |   T   |   U   |   R   |   D   |   A   |   Y   |
| :---: | :--: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **ε** |  0   |   1   |   2   |   3   |   4   |   5   |   6   |   7   |   8   |
| **S** |  1   | **0** | **1** | **2** |   3   |   4   |   5   |   6   |   7   |
| **U** |  2   |   1   |   1   |   2   | **2** |   3   |   4   |   5   |   6   |
| **N** |  3   |   2   |   2   |   2   |   3   | **3** |   4   |   5   |   6   |
| **D** |  4   |   3   |   3   |   3   |   3   |   4   | **3** |   4   |   5   |
| **A** |  5   |   4   |   3   |   4   |   4   |   4   |   4   | **3** |   4   |
| **Y** |  6   |   5   |   4   |   4   |   5   |   5   |   5   |   4   | **3** |

Вот так, собственно, и выглядит большинство решений из мира динамического программирования. Кстати, это решение имеет название — алгоритм Вагнера-Фишера. Забавный факт: этот алгоритм практически параллельно опубликовали разные группы незнакомых учёных с разных концов планеты, в эпоху, когда ещё и интернета не было. Товарищи Вагнер и Фишер, кстати, были далеко не первыми.

Давайте теперь рассмотрим, в чем его отличия от решения перебором.

### Анализ решения

Как уже было сказано, наивное решение *(решение перебором)* этой задачи простой рекурсией имеет временную сложность O(3^n) *(переформулировать: может быть, "занимает х времени?")* , но не требует лишней памяти — значит, O(1) по памяти. 

Какие издержки у динамического решения? Для простоты, давайте представим, что сравниваются слова равной длины, по n символов в слове. Всё решение сводится к заполнению таблицы с n+1 строчками (отдельная для пустой строки ε), и n+1 столбиками. Значит, используется (n+1)^2 ячеек. Не будем считать копейки, и округлим количество ячеек до n^2. Для каждой ячейки мы будем проверять трёх её соседей, что требует константного времени O(1) *(подробнее о константном времени)*. Значит, на заполнение всей таблицы потребуется O(n^2) операций.

Какой будет расход памяти? Элементарно — по количеству ячеек! *(переформулировать: "Расход времени будет вестись по количеству ячеек")* Получаем O(n^2) стоимости по памяти. 

Если слова разной длины, то можно либо смотреть по самому длинному, либо чуть-чуть усложнить формулу сложности. Например, если первое слово имеет длину n, а второе — m, то потребуется O(nm) времени и O(nm) памяти.



## Итог

Думаю, *(удалить "думаю")* что основная идея динамического программирования должна прослеживаться в представленном примере: мы жертвуем солидным количеством памяти (O(nm) вместо O(1)), но получаем просто сумасшедший выигрыш во времени (O(nm) против O(3^n)). 

Для чистоты совести *(удалить вставку о совести)* коротко перечислим все ключевые особенности динамического программирования.

**Преимущества**:

- Скорость: главное достоинство динамического программирования, вокруг которого мы танцуем с начала статьи. Нерешаемые задачи становятся решаемыми, в большинстве случаев — за квадратичное время *(расшить, что такое квадритичное время)*!
- Элегантность: *(универсальность?)* One Ring to rule them all — создание компактной системы из нескольких правил для заполнения таблицы гарантирует решение задачи на любых данных. Ни исключений, ни пограничных случаев, несколько строчек — и сложная проблема решена. Фантастика. *(убрать фантастику)*
- Точность: так как алгоритм динамического программирования рассмотрит абсолютно все возможные варианты и сценарии, он гарантированно обнаружит самое оптимальное решение. Никакой потери точности, никакой аппроксимации *(переформулировать: "никаких приблизительных ответов?")*. Если решение существует — оно будет найдено.  

**Проблематика**:

- Память: в большинстве случаев алгоритмы из динамического программирования стоят квадратичного потребления памяти *(о квадритичности выше)*, что само по себе в восторг не приводит никого.

- Когнитивная нагрузка: компактная система правил выглядит великолепно, но этот ланч не бесплатен — ведь для составления, или хотя бы понимания этих систем правил необходимо научиться “думать на динамическом программировании”. Это является причиной довольно спорной репутации динамического программирования. *(переформулировать блок более нейтрально)*



## Области применения

Динамическое программирование, исходя из его достоинств и недостатков, совсем не теоретическая конструкция, не выходящая за рамки научных работ, совсем нет. *(совсем нет - убрать)* Оно пользуется популярностью во многих прикладных областях. Чтоб не размазывать мысль о множестве разных наук, будь то прикладная математика, машиностроение, теории управления или прогнозирование финансовых данных, скажу *(стиль: "скажем")* пару слов только об одной.

Называется эта наука биоинформатикой. Если в двух словах — она исследует “оцифровывание” биологического материала, а так же хранение и анализ полученной информации. В этой науки сотни захватывающих аспектов, и она ставит перед разработчиками очень серьезные задачи, ведь данных невероятно много. Например, в геноме человека около трёх миллиардов пар нуклеотидов (кирпичиков ДНК). Одна пара обычно кодируется одним байтом, в итоге выходит около трёх миллиардов байт информации на один-единственный геном — три гигабайта данных на подопытного.

Один геном проблемы не делает — подумаешь, три гигабайта. Вот только геномы сами по себе малоинтересны, их нужно сравнивать с другими геномами. Чтоб обнаружить мутации в геноме конкретного человека, нужно сначала “выровнять” его с другими, референсными геномами (выровненными и размеченными заранее). Возможных вариантов этого выравнивания может быть огромное количество, но нужно найти самый правдоподобный из них. То есть вариант, у которого максимальная вероятность возникновения. Например, вариант с наименьшим количеством мутаций. Если принять во внимание, что генетический код обычно хранятся в виде очень длинных строк, состоящих из разных букв, то пример с Расстоянием Левенштейна начинает играть новыми красками. Эта задача, потенциально приводящая к комбинаторному взрыву *(уточнить: что это такое?)*, замечательно решается методами динамического программирования!

Если интересно, почитайте про Multiple Sequence Alignment (MSA): https://en.wikipedia.org/wiki/Multiple_sequence_alignment#Dynamic_programming

Это лишь один маленький и очень упрощенный пример. На самом деле, биоинформатика буквально живет динамическим программированием. Построение молекулярных деревьев, чтоб понять, как именно и в какой последовательности происходила эволюция? Динамическое программирование. Эффективный перевод генетической информации (например, из кусочка кожи) в длиннющую строку в базе данных? Динамическое программирование. Если 15 лет назад полное считывание генома (это называется секвенированием) имело себестоимость в десятки миллионов долларов, то сегодня эта услуга стоит одну-две тысячи долларов, и потихоньку дешевеет дальше. Этот скачок произошел не столько за счёт роста нашей вычислительной мощности, сколько за счёт появления эффективных алгоритмов. Такие дела. *(такие дела - убрать)*

