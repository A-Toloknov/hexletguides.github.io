---
title: Что такое время
subtitle: Или как не наступить на временнЫе грабли
description: Как современный компьютер хранит информацию, сколько сейчас времени,
как он отсчитывает секунды, почему почти никогда не ошибается и как с ним работать
image:
author: Вериго Александр
---

## Как компьютер определяет человеческое время?

Представим ситуацию, что Вы откопали в кладовой старый компьютер и любопытства ради
решили попробовать его включить. На удивление компьютер запускается, несмотря на
10 лет простоя. Но есть небольшая проблема: он уверен, что сегодня 1 января 1970
года. Такая ситуация не может не заставить задуматься, как компьютеры
хранят текущее время? У них нет внутри никаких пружин или маятников, которые
могли бы отсчитывать секунды, как в часах. Так как же они показывают верное
время даже если отключить их на несколько часов? И почему ваш компьютер перепутал
время, только проведя 10 лет в кладовке, а не делал это на каждый перезапуск?

### Маятник как первый секундомер

Чтобы разобраться в этом вопросе, нам стоит сначала дать ответ на то, как мы в
принципе можем точно измерять время. На самом деле, это не такая простая задача,
когда под рукой нет часов. Да, мы всё ещё можем отсчитывать дни, месяцы и годы,
мы даже можем разбить день на часы. Но тяжело найти ориентир, который мог бы нам
подсказать количество прошедших секунд.

Традиционно принято считать, что первым эту задачу решил итальянский ученый XVII
века [Галилео Галилей](https://ru.wikipedia.org/wiki/%D0%93%D0%B0%D0%BB%D0%B8%D0%BB%D0%B5%D0%B9,_%D0%93%D0%B0%D0%BB%D0%B8%D0%BB%D0%B5%D0%BE).
Его биографы утверждают, что Галилео, которому нужно было точно знать, сколько длился
тот или иной эксперимент, для измерения времени считал количество своих
сердцебиений. По легенде, однажды он наблюдал за раскачивающимся канделябром в кафедральном
соборе Пизы и заметил, что каждое колебание канделябра занимало одинаковое
количество сердцебиений, и не изменялось даже со временем, когда амплитуда
движения затухала. Таким образом он понял, что колебания маятника позволяют
более точно засекать время.

### Можно ли использовать колебания для подсчета времени в компьютере?

Когда в 70-е - 80-е годы инженеры впервые столкнулись с задачей отсчета
человеческого времени, как ни странно, они обратились к трудам итальянского ученого.
Дело в том, что маятник - не единственный возможный источник колебаний. У любого
современного персонального компьютера есть своеобразное "сердце" - Центральное
процессорное устройство (ЦПУ) или просто процессор. Это очень сложное устройство,
которое выполняет множество функций, но для нас важно то, что внутри него есть
небольшое устройство, которое, когда через него проходит ток, испускает равномерные
электрические колебания с одинаковой [частотой](https://en.wikipedia.org/wiki/Clock_rate).
Частота этих колебаний измеряется в Герцах (Гц) и определяет количество операций,
которое процессор может выполнить за одну секунду.

Представим, что у нас есть одноядерный процессор с частотой 1 Гц. Такой процессор
может выполнять одну операцию за одну секунду, и чтобы отсчитывать с его помощью
время мы можем просто хранить количество колебаний процессора. К сожалению,
если мы будем использовать единственную доступную нам операцию в секунду для
увеличения счетчика колебаний, то наш процессор будет совершенно непригоден
для чего либо ещё, потому что для остальных программ не останется места.
Конечно, современные процессоры не такие медленные, их частота измеряется в
Гигагерцах (ГГц), то есть в 1 000 000 000 операций в секунду. Но даже имея
такую мощь, чтобы засечь время, нам бы пришлось считать каждое колебание процессора.

Для решения этой проблемы был придуман кварцевый генератор. Это устройство
представляет собой тончайшую кремниевую пластину, которая под воздействием
электрического напряжения начинает равномерно расширяться и сжиматься обратно,
[генерируя небольшой электрический заряд на своей поверхности](https://ru.wikipedia.org/wiki/%D0%9F%D1%8C%D0%B5%D0%B7%D0%BE%D1%8D%D0%BB%D0%B5%D0%BA%D1%82%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D1%8D%D1%84%D1%84%D0%B5%D0%BA%D1%82)
Таким образом, механические колебания пластины сопровождаются синхронными, равномерными
колебаниями электрического заряда.

```
                      |            |
                      |------------|
    -->--->--->-->--->| Генератор  | >>>>>>>>>
      Переменный ток  |------------|  100 Гц
                      |            |
```

Полученные равномерные колебания принято называть таймером, потому что позволяют
процессору синхронизировать производимые им операции во времени. Таким образом,
у компьютера есть свой собственный таймер и своё собственное понимание времени.

### От компьютерного времени к человеческому

Получается, что у компьютера есть таймер, но нет нужды замерять человеческое время,
оно для него довольно бесполезно. Как правило, эту задачу на себя берут операционные
системы (ОС). Поскольку ОС обычно знает, с какой частотой работает кварцевый генератор,
то она знает и сколько времени проходит между каждым срабатыванием таймера
(срабатывание таймера называют тик (tick) или джиффи (jiffy)). Это посчитать
довольно просто, если генератор работает на частоте 100 Гц, то период между
тиками равен 1/100 секунды или 10 миллисекундам. Операционная система создает в памяти
переменную, которую обычно называют jiffies, и увеличивает ее на единицу каждый раз,
когда процессор оповещает ее, что произошел новый тик. Соответственно, чтобы узнать,
как долго включен компьютер, системе достаточно умножить размер периода между тиками
на количество этих самых тиков. А чтобы узнать текущее время, достаточно добавить
прошедшее время к времени на момент старта системы. Но как узнать человеческое время
на момент старта системы?

### RTC (Real Time Clock), или Часы реального времени

Интересно, но первые персональные компьютеры, такие как [IBM PC](https://en.wikipedia.org/wiki/IBM_Personal_Computer#Design_process)
или [Apple II](https://en.wikipedia.org/wiki/Apple_II), не умели следить за тем,
сколько прошло время после выключения, а [спрашивали его на старте](https://www.youtube.com/watch?v=X3aqJQPQKhs).
Для решения этой задачи снова пригодился кварцевый генератор. Поскольку ему
неважно из какого источника получать электрическое напряжение, то довольно быстро
поняли, что достаточно подключить генератор к обычной литиевой батарейке, чтобы
получать равномерные электрические колебания. Если в эту схему еще добавить
бинарный счетчик, который увеличивается на каждое колебание, то мы получим
устройство, которое может фиксировать человеческое время. Оно так и называется -
RTC (Real Time Clock), или Часы реального времени. Частота колебаний на
выходе из RTC обычно 32 768 Гц или 2^15 Гц, что удобно использовать в бинарных счетчиках.

```
                                          RTC
|-------------------- |---------- |-------------------- |                                     |
|                     |           |                     |         32 768 Гц                   |
| Литиевая батарейка  | ->->->->  | Кварцевый генератор | >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>    |
|                     | ток       |                     | Равномерные электрические колебания | Бинарный счетчик
|                     |           |                     |                                     |
|-------------------- |---------- |-------------------- |                                     |
```

Как оказалось, наш старый сервер перепутал время именно из-за того, что
батарейка в его часах реального времени села от старости: когда сервер запустился,
он не смог считать время из RTC и выставил стандартное стартовое время - 1 января
1970 года.

### Network Time Protocol

Итак, RTC позволяет компьютеру отсчитывать миллисекунды даже когда он выключен.
Но стандартные RTC имеют погрешность 1,7 - 8,6 секунд в день, значит за год они
могут потерять целый час. Мы иногда сталкиваемся с этой проблемой в реальной жизни,
когда нам приходится поправлять время на наручных кварцевых часах или на
микроволновке, которые тоже используют RTC. Но нам никогда не приходится делать
этого на компьютере. Да и на старте компьютер больше не спрашивает текущее время.
Когда он подключается к сети интернет, он может использовать NTP (Network Time
Protocol - протокол сетевого времени) для того, чтобы синхронизироваться с сервером
точного времени в сети интернет. Этот протокол даже учитывает время передачи
данных между источником и компьютером и компенсирует его. В публичной сети он
позволяет достигать точности 10 мс.

### Как это работает все вместе?

```
|       | Включение компьютера   |                       | Периодически опрашивает NTP  |      |
|------ |----------------------- |---------------------- |----------------------------- |----- |
| RTC   | ->->->->               | Операционная система  | ->->->->                     | NTP  |
| RTC   | <-<-<-<-               | Операционная система  | <-<-<-<-                     | NTP  |
|------ |----------------------- |---------------------- |----------------------------- |----- |
|       | Выключение компьютера  |                       |                              |      |
```

Когда наш компьютер выключен, RTC продолжает работу и отсчитывает время.
Когда мы нажимаем кнопку запуска, операционная система забирает время из RTC и
начинает отслеживать время самостоятельно, используя таймер процессора. Время от
времени, операционная система по NTP получает точное время и поправляет свой
внутренний счетчик. Когда мы выключаем компьютер, за дело снова берется RTC.

## Про таймстампы и эпохи

Как уже говорилось, операционная система для того, чтобы отслеживать человеческое
время, создает в памяти компьютера переменную jiffy, в которой хранит количество
тиков с момента старта системы. Но как с помощью этого показывать человеку календарь,
который мог бы идти на несколько лет вперёд или назад.

### А что такое Unix-таймстамп и epoch?

В 70-е годы прошлого века, эту проблему решили инженеры из Bell Labs при разработке
операционной системы Unix (которая заложит фундамент для появления современных
Linux и MacOS). Они договорились, что в системе будет переменная, которая будет
увеличиваться на каждый тик генератора, начиная от какой-то заданной даты.
Такую фиксированную дату принято называть epoch. Под эту переменную отводилось
целое число со знаком (eng. signed integer) размером в 32 бита (то есть от
−2 147 483 648 (-2^31) до 2 147 483 647 (2^31−1)). Подавляющее большинство
генераторов тогда работали на частоте 60 Гц, то есть 60 тиков в секунду,
поэтому было решено хранить в этой переменной 1/60 секунды, и соответственно,
она могла представлять временной промежуток не более 829 дней.
В [версии Unix от 1971 года отсчет начинался с 1971-01-01 00:00:00](http://man.cat-v.org/unix-1st/2/sys-time).
[На следующий год с 1972-01-01 00:00:00](https://minnie.tuhs.org/cgi-bin/utree.pl?file=V3/man/man2/time.2).
Переставлять время каждый год было довольно неудобно, поэтому в 4 версии Unix в
1973 году за [epoch была взята дата 1970-01-01 00:00:00](https://minnie.tuhs.org/cgi-bin/utree.pl?file=V4/man/man2/time.2),
а в переменной стали хранить не 1/60 секунды, а полную секунду. Позже это вошло
в международный стандарт и используется по сей день.

Если на Вашем компьютере установлена операционная система семейства Linux или MacOS,
то Вы можете увидеть текущий Unix-timestamp, введя в терминале `date +"%s"`.
Операционная система Windows, вдохновившись примером, тоже считает время, отталкиваясь
от временной отметки, но выбрали для этого не абстрактный 1970 год, а 1601, потому
что это первый год Грегорианского календаря.

### Проблема 2038 года

Поскольку время хранится в целочисленной 32-битовой переменной и это просто количество
секунд с какого-то момента во времени, то самое большое количество секунд, которое
мы можем использовать - это 2 147 483 647 (2^31−1). Если прибавить это количество
к epoch, то мы получим 19 января 2038 03:14. Что произойдет с системой, когда
эта дата наступит и пройдет еще одна секунда? Для ответа на этот вопрос нам придется
взглянуть на то, как это число выглядит в двоичной системе исчисления, а именно:

`01111111111111111111111111111111` (0 и 31 единица)

Если это число увеличить на единицу, то оно превратится в

`10000000000000000000000000000000` (1 и 31 ноль),

(Картинка, как первое число становится вторым?)

что в десятичной системе равно −2 147 483 648, то есть число перейдет от
самого большого положительного к самому маленькому отрицательному. И система
начнет показывать дату равную 1 января 1970 года - 2 миллиарда секунд, то есть
13 декабря 1901 года.

Но не стоит волноваться, проблема уже решена - большинство систем уже используют
64 битовые числа для хранения времени. Этого хватит, чтобы
не столкнуться с проблемой до 15:40 4 декабря 292 277 026 596 года.

### Проблема 2000 года, или Y2K bug

> "640 килобайт памяти должно быть достаточно для кого угодно".

Билл Гейтс, 1981 г.

На самом деле в истории уже была такая ситуация. В 60-70-е годы прошлого
столетия, когда люди только начали писать программное обеспечение для
компьютеров, компьютерная память стоила больших денег и большинство
компьютеров обходились несколькими килобайтами памяти. Соответственно, память
нужно было экономить и программисты решили записывать даты в формате: ДД.ММ.ГГ.

Какую проблему это порождало? Допустим, у нас есть человек по имени Боб, у
которого дата рождения записана как 01.11.19. Он родился в 1919 году, и ему чуть
больше 100 лет. А есть человек по имени Фред и он родился 02.11.19, но ему
всего два года, потому что он родился в 2019 году. И, конечно, люди, сталкиваясь
с таким форматом дат, могут исходить из контекста и выяснить, кто старик, а кто
младенец, но компьютер этого сделать обычно не может.

Люди, которые писали код в 60-70-е годы даже не предполагали, что их код может
дожить до 2000 года, поэтому использование двух цифр вместо четырёх было нормальной
оптимизацией. Но когда начал приближаться 2000 год, а многие компании всё ещё
использовали тот код из 70-х, началась паника на тему, что произойдет, когда 99
год сменится на 00. Тогда в мире ходили самого разного рода слухи, в том числе,
что банкоматы в этот момент начнут плеваться деньгами, а самолеты начнут падать.
Но благодаря тому, что баг был вовремя замечен, проблему удалось исправить в
большинстве  систем вовремя.

## О локальном времени, таймзонах и боли

Давайте представим, что нам нужно написать приложение, которое должно каждый
день в 12 часов дня отправлять пользователю уведомление о том, что наступил
полдень. Такое малополезное приложение. Допустим, что мы живем в Лондоне
и приложение планируем использовать только там, пишем код мы зимой, поэтому
разницы с UTC (Coordinated Universal Time или Всемирное координированное время)
у нас нет.

Приложение работает хорошо, и вот уже наступил последний день марта
и вдруг на следующий день уведомление всем отправилось в час дня, а не в полдень.
Дело в том, что мы просто прикрутили таймер, который срабатывает раз в 24 часа, а
в последний день марта в Англии перевели время на час вперед на летнее время.
Мы быстро исправили ситуацию, заменили таймер на планировщик задач, который
срабатывает, используя локальное время компьютера.

## Выводы

- В любом современном ПК есть процессор, который умеет производить колебания
с равными интервалами.
- Зная период этих колебаний, операционная система компьютера может считать
человеческое время.
- С помощью протокола NTP операционная система может обращаться к серверам
точного времени, для скорректировать своих часов
- Когда компьютер выключен, время считает специальное устройство - RTC, которое
питается от батареи
